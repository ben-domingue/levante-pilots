
```{r load-data}
source(here::here("assessment/colombia/stage2/_setup.R"))


trog <- read_rds(file = here("assessment","colombia","stage2","data_processed","trials_coded.rds")) |>
  filter(!is.na(corpus_trial_type), task_id=="trog") |>
  mutate(correct = ifelse(corpus_trial_type=="number line slider", score_ntl(item, answer, response, NUMBERLINE_TOLERANCE), correct))

# need any of this?
#pdat <- read_rds(file = here("assessment","colombia","stage2","data_processed","participants.rds"))
```



Compute sumscores, create abbreviations and unique item_id.

```{r}
trog_cleaned <- trog |>
  filter(!is.na(corpus_trial_type), !is.na(age)) 
  # item_id = paste(task_abbrev,item,answer), # <- need a unique item id

trog_items <- trog_cleaned |> select(corpus_trial_type, item, answer) |>
  distinct() |>
  mutate(item_id = paste("item",1:n(),sep='_'))

trog_cleaned <- trog_cleaned |>
  left_join(trog_items)
```

```{r, warning=F, message=F}
trog_sumscores <- trog_cleaned  |> 
  group_by(user_id, corpus_trial_type, age) |>
  summarise(correct = mean(correct)) 

ggplot(trog_sumscores, aes(x = age, y = correct)) + 
  geom_point(alpha = .5) + 
  geom_smooth() +
  ylim(0,1) + 
  facet_wrap(.~corpus_trial_type)
```

```{r, message=F, warning=F}
acc_by_s <- trog_cleaned |> 
  group_by(user_id, age) |>
  summarise(correct = mean(correct),
            n = n()) 

# too many trials...
acc_by_s |>
  filter(n > 90)
# user_id = "yU1rpOgCAyPqkQh3F9oXQXJZC6B2" has 296 trials (!)

acc_by_s |> filter(n <= 90) |>
  ggplot(aes(x=age, y=correct, size=n)) +
  geom_smooth() +
  geom_point(alpha=.3) 
```


# IRT models

```{r}
source(here("assessment","colombia","stage2","irt_helpers.R"))

task_data_coded <- trog_cleaned |> 
  mutate(chance = .25) |>
  select(matches("id"), age, corpus_trial_type, item_id, chance, correct, rt, server_timestamp)

# identify too slow/fast RTs
# TODO: check min/max values + why are some RTs NA
min_rt <- 0.5
max_rt <- 50
task_data_rt <- task_data_coded |>
  mutate(rt = as.numeric(rt) / 1000, rt_fast = rt < min_rt, rt_slow = rt > max_rt) |>
  filter(is.na(rt) | rt > 0)

task_data_nested <- task_data_rt |>
  filter(is.na(rt_fast) | !rt_fast, is.na(rt_slow) | !rt_slow) |> # remove too slow/fast RTs
  select(-starts_with("rt")) |> # drop all RT columns
  nest(data = everything(), .by = task_id) # nest data by task


task_data_prepped <- task_data_nested |>
  mutate(data_filtered = map(data, \(df) df |> filter_repeat_runs() |>
                               dedupe_items() |> remove_no_var_items()),
         data_prepped = map(data_filtered, to_mirt_shape))
```

Let's start by just fitting our general set of models. 

```{r, message=F}
item_types <- c("Rasch", "2PL") #, "3PL") # set of parameterizations
model_types <- c(1, 2) # set of dimensionalities

# add arguments for model fitting to data
task_data_args <- task_data_prepped |>
  # duplicate rows per dimensionality x parameterization
  expand_grid(model_type = model_types, item_type = item_types) |>
  # generate model string with item constraints + dimensionality
  mutate(model_str = pmap_chr(list(data, data_prepped, item_type, model_type),
                              generate_model_str)) |>
  # pull out chance values
  mutate(guess = map(data_filtered, # TODO: check that this gives correct order
                     \(df) df |> distinct(item_inst, chance) |> pull(chance)))

task_models <- task_data_args |>
  mutate(mod = pmap(list(data_prepped, item_type, model_str, model_type,
                         task_id, guess), fit_mirt))
```
Now let's take a look!

```{r}
# get results
task_results <- task_models |>
  mutate(coefs = map(mod, mirt_coefs),
         scores = pmap(list(mod, data_filtered, data_prepped), mirt_scores),
         aic = map_dbl(mod, mirt_aic))

# best fitting model for each task
task_best <- task_results |>
  group_by(task_id) |>
  filter(aic == min(aic)) |>
  ungroup() |>
  select(task_id, item_type, model_type, coefs, scores)

# scores from best fitting model
task_scores <- task_best |>
  select(task_id, item_type, scores) |>
  unnest(scores) |>
  mutate(score_type = glue("ability ({item_type})")) |>
  select(task = task_id, user_id, age, score_type, score = ability)
```

## 2PL 

```{r}
trog_items <- trog_cleaned |>
  select(corpus_trial_type, item_id, item, answer) |> # answer
  distinct()

trog_coefs <- task_best$coefs[[1]] |>
  mutate(item_id = str_sub(item, 1, -3)) |>
  select(-item) |>
  left_join(trog_items)

ggplot(trog_coefs |> 
           pivot_longer(a1:a2, names_to = "dim", values_to = "a"), 
       aes(x = d, y = a, col = corpus_trial_type)) + 
  geom_point(alpha = .5) + 
  facet_wrap(~dim)
```

```{r}
trog_coefs |>
  arrange(desc(a1)) |>
  knitr::kable()
```


## 1PL 


```{r}
trog_coefs <- task_results$coefs[[2]] |>
  mutate(item_id = str_sub(item, 1, -3)) |>
  select(-item) |>
  left_join(trog_items)

ggplot(trog_coefs, 
       aes(x = -d, y = a1, col = corpus_trial_type)) + 
  geom_point(alpha = .5) +
  ggrepel::geom_label_repel(aes(label = item), size =2) + 
  xlab("Difficulty") + 
  ylab("Discrimination")
```


```{r}
task_scores |>
  ggplot(aes(x=age, y=score)) +
  geom_point() + theme_classic() +
  geom_smooth()
```

