```{r load-data}
source(here::here("assessment/colombia/stage2/_setup.R"))

trials_coded <- read_rds(here("assessment/colombia/stage2/data_processed/trials_coded.rds"))
participants <- read_rds(here("assessment/colombia/stage2/data_processed/participants.rds"))
```

```{r}
# tasks to include in these analyses
irt_tasks <- c("egma-math",
               "matrix-reasoning",
               "mental-rotation",
               "same-different-selection",
               "theory-of-mind",
               "trog")

# excluded tasks
# setdiff(trials_coded$task_id, irt_tasks)

task_data <- trials_coded |>
  # only relevant tasks + not missing item + has response or correct
  filter(task_id %in% irt_tasks,
         !is.na(item),
         !is.na(response) | !is.na(correct)) |>
  # chronological order
  arrange(user_id, run_id, server_timestamp) |>
  # curly braces in items cause regex problems
  mutate(item = item |> str_remove_all("[\\{\\}]")) |>
  # compute number of distractors + chance level
  mutate(distractors = distractors |> str_count(":") |> na_if(0),
         chance = 1 / (distractors + 1)) |>
  select(matches("_id"), age, corpus_trial_type, assessment_stage, item,
         answer, chance, response, correct, rt, server_timestamp)

# same-different-selection needs special processing to identify items
sds <- task_data |>
  filter(task_id == "same-different-selection") |>
  filter(corpus_trial_type != "something-same-1") |>
  arrange(server_timestamp) |>
  mutate(different = str_extract(item, "different")) |> # trials are "different" or NA
  group_by(user_id, run_id, corpus_trial_type) |> # within subtask (e.g. 3-match)
  mutate(trial_i = consecutive_id(different), # number trials sequentially
         trial_i = if_else(is.na(different), trial_i, trial_i - 1)) |> # "different" trials are actually part of previous trial
  group_by(user_id, run_id, corpus_trial_type, trial_i) |>
  mutate(i = 1:n()) |> # sequential number within multiple "different" trials
  ungroup() |>
  mutate(response = as.character(i) |>
           fct_recode("first" = "1", "second" = "2",
                      "third" = "3", "fourth" = "4")) |>
  group_by(user_id, run_id, corpus_trial_type) |>
  mutate(trial = consecutive_id(trial_i)) |> # renumber trials sequentially
  group_by(user_id, run_id, corpus_trial_type) |>
  mutate(item_id = if (all(trial == 1)) paste(corpus_trial_type, i) else paste(corpus_trial_type, trial, response)) |>
  ungroup() |>
  select(-different, -trial_i, -i, -response, -trial)

# # same-different-selection item identification with within-block equivalence
# sds <- task_data |>
#   filter(task_id == "same-different-selection") |>
#   filter(corpus_trial_type != "something-same-1") |>
#   arrange(server_timestamp) |>
#   mutate(different = str_extract(item, "different")) |> # trials are "different" or NA
#   group_by(user_id, run_id, corpus_trial_type) |> # within subtask (e.g. 3-match)
#   mutate(trial_i = consecutive_id(different), # number trials sequentially
#          trial_i = if_else(is.na(different), trial_i, trial_i - 1)) |> # "different" trials are actually part of previous trial
#   group_by(user_id, run_id, corpus_trial_type, trial_i, different) |>
#   mutate(i = 1:n()) |> # sequential number within multiple "different" trials
#   ungroup() |>
#   mutate(item_id = case_when(
#     # different trial -> item_id = "[subtask] different [i]"
#     !is.na(different) ~ paste(corpus_trial_type, different, i),
#     # non different trial in X-match subtask -> item_id = "[subtask] same"
#     str_detect(corpus_trial_type, "^\\d-") ~ paste(corpus_trial_type, "same"),
#     # otherwise -> item_id = [subtask]
#     TRUE ~ corpus_trial_type)) |>
#   select(-different, -trial_i, -i)

# sds |>
#   group_by(item_id) |>
#   summarise(n = n(), n_users = n_distinct(user_id))

# egma needs special processing to identify items
egma <- task_data |>
  filter(task_id == "egma-math") |>
  # recode subtasks for shorter item strings
  mutate(corpus_trial_type = corpus_trial_type |> fct_recode(
    num_id = "number identification",
    num_comp = "number comparison",
    miss_num = "missing number",
    add = "addition",
    sub = "subtraction",
    line_4afc = "number line 4afc",
    mult = "multiplication",
    line_slid = "number line slider",
    frac = "fraction"
  )) |>
  # number line trials have long names with only identifying info being last num
  mutate(item = if_else(str_detect(corpus_trial_type, "line"),
                        str_extract(item, "\\d+$"),
                        item)) |>
  # item_id = "[subtask] [item] [answer]"
  mutate(item_id = paste(corpus_trial_type, item, answer))

# score just number line trials
threshold <- 0.15
numberline <- egma |>
  filter(corpus_trial_type == "line_slid") |>
  mutate(correct = pmap_lgl(list(item, answer, response), \(item, answer, response) {
    # get slider max from item ("{'0': 0, '1': [max_value]}")
    max_value <- as.numeric(str_extract(item, "\\d+$"))
    # get distance b/w response & answer, scale to max, compare to threshold
    abs(as.numeric(response) - as.numeric(answer)) / max_value < threshold
  })) |>
  mutate(chance = threshold * 2)

# recombine numberline with rest of egma
egma_numberline <- egma |>
  filter(corpus_trial_type != "line_slid") |>
  bind_rows(numberline)

# theory of mind is separated by assessment_stage +
# has special processing to identify items +
# hostile attribution correctness recoding
hostile_values <- read_csv(here("assessment/colombia/stage2/task_analyses/hostile-attribution-coding.csv"))
tom <- task_data |>
  filter(task_id == "theory-of-mind") |>
  mutate(task_id = assessment_stage) |> # treat hostile-attribution as task
  group_by(user_id, run_id, task_id, item, corpus_trial_type) |>
  mutate(i = 1:n(), n = n()) |> # sequentially number items
  ungroup() |>
  # item_id = "item [question type]" (+ "[i]" if multiple same type items)
  mutate(item_id = paste(item, str_remove(corpus_trial_type, "_question")),
         item_id = paste(item_id, i)) |>
         # item_id = if_else(n == 1, item_id, paste(item_id, i))) |>
  select(-i, -n) |>
  left_join(hostile_values) |>
  mutate(correct = if_else(task_id == "hostile-attribution",
                              value %in% c("purpose", "hostile"),
                              correct)) |>
  select(-value)

task_data_coded <- task_data |>
  # replace separated out data
  filter(!task_id %in% c("egma-math", "same-different-selection", "theory-of-mind")) |>
  bind_rows(sds) |> bind_rows(egma_numberline) |> bind_rows(tom) |>
  # id other items as just item
  mutate(item_id = if_else(!is.na(item_id), item_id, item)) |>
  # hyphens in item names mess up mirt constraints (yes really)
  mutate(item_id = item_id |> str_replace_all("-", "_")) |>
  select(matches("id"), age, corpus_trial_type, item_id, chance, correct, rt, server_timestamp)

# identify too slow/fast RTs
# TODO: check min/max values + why are some RTs NA
min_rt <- 0.5
max_rt <- 50
task_data_rt <- task_data_coded |>
  mutate(rt = as.numeric(rt) / 1000, rt_fast = rt < min_rt, rt_slow = rt > max_rt) |>
  filter(is.na(rt) | rt > 0)

# some plotting to look at rt filters
# ggplot(task_data_rt, aes(x = rt)) +
#   facet_wrap(vars(task_id)) +
#   geom_density() +
#   geom_vline(xintercept = c(min_rt, max_rt), color = "red", linetype = "dashed") +
#   scale_x_log10(labels = scales::comma, breaks = 10 ^ seq(-2, 2)) +
#   labs(x = "Response time (seconds)")
# task_data_rt |> filter(rt_fast) |> count(task_id)
# task_data_rt |> filter(rt_slow) |> count(task_id)

task_data_nested <- task_data_rt |>
  filter(is.na(rt_fast) | !rt_fast, is.na(rt_slow) | !rt_slow) |> # remove too slow/fast RTs
  select(-starts_with("rt")) |> # drop all RT columns
  nest(data = everything(), .by = task_id) # nest data by task
```

```{r}
### functions to prep data for modeling

# filter to each users earliest run
filter_repeat_runs <- function(df) {
  df |>
    group_by(user_id) |>
    filter(server_timestamp == min(server_timestamp)) |> # user's earliest trial
    ungroup() |>
    distinct(user_id, run_id) |> # corresponding run id
    inner_join(df) # filter join
}

# add identifiers for each instance of each item
item_sep <- "_"
dedupe_items <- function(df) {
  df |>
    group_by(user_id, item_id) |>
    mutate(instance = seq_along(item_id)) |> # i
    ungroup() |>
    mutate(item_inst = glue("{item_id}{item_sep}{instance}")) # item_i
}

# remove items with no variance
remove_no_var_items <- function(df) {
  df |>
    group_by(item_inst) |>
    mutate(item_mean = mean(correct, na.rm = TRUE)) |> # item means
    ungroup() |>
    filter(item_mean > 0, item_mean < 1) # need to be between 0 and 1
}

# format data for mirt
to_mirt_shape <- function(df) {
  df |>
    mutate(correct = as.numeric(correct)) |> # values to numeric
    select(user_id, item_inst, correct) |>
    pivot_wider(names_from = "item_inst", values_from = "correct") |> # column for each item
    column_to_rownames("user_id") # user_id to rownames
}

# transform each task's data for modeling by applying above functions
task_data_prepped <- task_data_nested |>
  mutate(data_filtered = map(data, \(df) df |> filter_repeat_runs() |>
                               dedupe_items() |> remove_no_var_items()),
         data_prepped = map(data_filtered, to_mirt_shape))
```


```{r setup-models}
# generate model strings, using constraints for repeated items
# TODO: is kind of slow, could be probably improved
paste_c <- partial(paste, collapse = ",")
generate_model_str <- function(df, df_prepped, item_type, f) { # f = num factors
  params <- "d" # always have difficulty
  if (item_type != "Rasch") {
    # add slopes a[i] based on parameterization
    s <- as.numeric(str_extract(item_type, "^\\d")) - 1
    params <- c(params, paste0("a", 1:s))
  }
  items <- df |> pull(item_id) |> unique() # item ids
  constraints <- items |> map(\(item_id) {
    # get columns with item's instances
    matched <- colnames(df_prepped) |>
      keep(\(col) str_detect(col, glue("^{item_id}{item_sep}")))
    if (length(matched) > 1) {
      # constraint for item instance: (item_1, item_2, param)
      map_chr(params, \(p) glue("({paste_c(matched)},{p})")) |> paste_c()
    }
  }) |> compact() |> paste_c() # combine into CONSTRAIN statement
  constraint <- if (str_length(constraints) > 1) paste0("CONSTRAIN=", constraints) else ""
  # F[i] = 1-K statement for each factor
  factors <- map_chr(1:f, \(i) glue("F{i} = 1-{ncol(df_prepped)}"))
  # combine statements
  paste(c(factors, constraint), collapse = "\n")
}

item_types <- c("Rasch", "2PL") #, "3PL") # set of parameterizations
model_types <- c(1, 2) # set of dimensionalities

# add arguments for model fitting to data
task_data_args <- task_data_prepped |>
  # duplicate rows per dimensionality x parameterization
  expand_grid(model_type = model_types, item_type = item_types) |>
  # generate model string with item constraints + dimensionality
  mutate(model_str = pmap_chr(list(data, data_prepped, item_type, model_type),
                              generate_model_str)) |>
  # pull out chance values
  mutate(guess = map(data_filtered, # TODO: check that this gives correct order
                     \(df) df |> distinct(item_inst, chance) |> pull(chance)))
```

### Fit models

```{r fit-models}
set.seed(1234)

# wrapper to fit mirt model with supplied arguments
fit_mirt <- function(df, item_type, model_str, model_type, task_id, guess) {
  message(glue("fitting {item_type} model with {model_type} dims for {task_id}"))
  mirt(df, itemtype = item_type, model = model_str, guess = guess,
       technical = list(NCYCLES = 2000), verbose = TRUE)
}

# get item parameters of fitted mirt model
mirt_coefs <- function(mod) {
  coef(mod, simplify = TRUE)$items |> as_tibble(rownames = "item")
}

# get participant scores of fitted mirt model
mirt_scores <- function(mod, df, df_prepped) {
  scores <- fscores(mod, method = "MAP", verbose = FALSE)
  user_scores <- tibble(user_id = rownames(df_prepped),
                        ability = scores[,1]) # TODO: check this gives correct order
  df |> distinct(user_id, run_id, task_id, age) |>
    left_join(user_scores) |> select(-task_id)
}

# get AIC of fitted mirt model
mirt_aic <- function(mod) mod@Fit$AIC

# some manual debugging stuff
eg <- task_data_prepped |> filter(task_id == "egma-math") |> pull(data_filtered) |> pluck(1)
ggplot(eg, aes(x = item_mean)) +
  facet_wrap(vars(corpus_trial_type), scales = "free") +
  geom_density()
# tdp <- task_data_args |> slice(9)
tdp <- task_data_args |> filter(task_id == "egma-math")
dp <- tdp$data_prepped[[1]]
fm <- fit_mirt(dp, tdp$item_type[[1]], tdp$model_str[[1]],  tdp$model_type[[1]], tdp$task_id[[1]], tdp$guess[[1]])

# fit all the models!
task_models <- task_data_args |>
  mutate(mod = pmap(list(data_prepped, item_type, model_str, model_type,
                         task_id, guess), fit_mirt))
# error fitting Rasch for egma-math:
# Error in `mutate()`: In argument: `mod = pmap(...)`.
# Caused by error in `pmap()`: In index: 17.
# Caused by error: ! Number of items selected not equal to number of parameter names

# get each model's coefs, scores, AIC
task_results <- task_models |>
  mutate(coefs = map(mod, mirt_coefs),
         scores = pmap(list(mod, data_filtered, data_prepped), mirt_scores),
         aic = map_dbl(mod, mirt_aic))

# best fitting model for each task
task_best <- task_results |>
  group_by(task_id) |>
  filter(aic == min(aic)) |>
  ungroup() |>
  select(task_id, item_type, model_type, coefs, scores)

# scores from best fitting models
task_scores <- task_best |>
  select(task_id, item_type, scores) |>
  unnest(scores) |>
  mutate(item_type = fct_recode(item_type, "1PL" = "Rasch"),
         score_type = glue("ability ({item_type})")) |>
  select(task = task_id, user_id, age, score_type, score = ability)

# save all data + models + results
save(task_results,
     file = here("assessment/colombia/stage2/task_analyses/irt_models.RData"))

# save scores
write_rds(task_scores, here("assessment/colombia/stage2/scores/combined_scores.rds"))
```

```{r}
# item parameters
item_coefs <- task_results |>
  select(task_id, dims = model_type, params = item_type, coefs) |>
  unnest(coefs) |>
  select(-g, -u) |>
  pivot_longer(c(d, a1, a2), names_to = "term", values_to = "value") |>
  filter(!is.na(value)) |>
  mutate(params = fct_inorder(params), term = fct_inorder(term)) |>
  arrange(task_id, params, dims) |>
  mutate(model = paste(params, dims) |> fct_inorder()) |>
  group_by(model, term) |>
  filter(!all(value == 1))

# item parameters distributions
ggplot(item_coefs, aes(x = model, y = value, colour = term)) +
  facet_wrap(vars(task_id), scale = "free", nrow = 2) +
  geom_sina(size = 0.8) +
  scale_colour_ptol() +
  labs(x = "IRT model type", y = "Parameter value", colour = "Parameter")
ggsave("irt_params.png", width = 14, height = 6)
```
